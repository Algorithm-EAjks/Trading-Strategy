{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pancakeswap momentum trading\n",
    "\n",
    "This is an example strategy backtesting how to momentum trading on PancakeSwap.\n",
    "\n",
    "## Strategy and backtesting parameters\n",
    "\n",
    "Here we define all parameters that affect the backtest outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "\n",
    "# The starting date of the backtest\n",
    "# Note: At the moment, due to QsTrader internal limitation,\n",
    "# we define this as NYSE UTC trading hours\n",
    "start = pd.Timestamp('2020-12-01')\n",
    "\n",
    "# The ending date of the backtest\n",
    "end = pd.Timestamp('2022-01-01')\n",
    "\n",
    "# Start backtesting with $10k in hand\n",
    "initial_cash = 10_000\n",
    "\n",
    "# Prefiltering to limit the pair set to speed up computations\n",
    "# How many USD all time buy volume the pair must have had\n",
    "# to be included in the backtesting\n",
    "prefilter_min_buy_volume = 5_000_000\n",
    "\n",
    "# When this USD threshold of bonding curve liquidity provided is reached,\n",
    "# we ape in to the token on a daily close.\n",
    "min_liquidity = 250_000\n",
    "\n",
    "# How many tokens we can hold in our portfolio\n",
    "# If there are more new tokens coming to market per day,\n",
    "# we just ignore those with less liquidity\n",
    "max_assets_per_portfolio = 5\n",
    "\n",
    "# How many % of all value we hold in cash all the time,\n",
    "# so that we can sustain hits\n",
    "cash_buffer = 0.33\n",
    "\n",
    "# Use daily candles to run the algorithm\n",
    "candle_time_frame = TimeBucket.d1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating trading universe\n",
    "\n",
    "First let's import libraries and initialise our dataset client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Trading Strategy in Jupyter notebook environment, configuration is stored in /Users/moo/.tradingstrategy\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tradingstrategy\n",
    "except ImportError:\n",
    "    !pip install tradingstrategy\n",
    "    import site\n",
    "    site.main()\n",
    "\n",
    "from tradingstrategy.client import Client\n",
    "\n",
    "client = Client.create_jupyter_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's create a pair universe for PancakeSwap.\n",
    "We will create a dataset of 2d candles that trade on PancakeSwap on Binance Smart Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our trading universe has 5357 pairs that meet the prefiltering criteria\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tradingstrategy.chain import ChainId\n",
    "from tradingstrategy.pair import PandasPairUniverse\n",
    "\n",
    "columnar_pair_table = client.fetch_pair_universe()\n",
    "\n",
    "exchange_universe = client.fetch_exchange_universe()\n",
    "\n",
    "all_pairs_dataframe = columnar_pair_table.to_pandas()\n",
    "\n",
    "our_exchange = exchange_universe.get_by_chain_and_slug(ChainId.bsc, \"pancakeswap-v2\")\n",
    "our_pairs: pd.DataFrame = all_pairs_dataframe.loc[\n",
    "    (all_pairs_dataframe['exchange_id'] == our_exchange.exchange_id) &  # Trades on Sushi\n",
    "    (all_pairs_dataframe['buy_volume_all_time'] > 500_000)  # 500k min buys\n",
    "]\n",
    "\n",
    "# Create a Python set of pair ids\n",
    "wanted_pair_ids = our_pairs[\"pair_id\"]\n",
    "\n",
    "# Make the trading pair data easily accessible\n",
    "pair_universe = PandasPairUniverse(our_pairs)\n",
    "\n",
    "print(f\"Our trading universe has {len(pair_universe.get_all_pair_ids())} pairs that meet the prefiltering criteria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Construct backtesting universe\n",
    "\n",
    "Get daily candles and filter them against our wanted pair set.\n",
    "\n",
    "\n",
    "We take all trading pairs registered on  (as the writing of this all Uniswap v2 compatible exchanges).\n",
    "As the number of trading pairs is very high (50k+).\n",
    "Most of these trading pairs are random noise and crap.\n",
    "We reduce the number of trading pairs to speed up the backtest simulation, but this also introduce some\n",
    "survivorship bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datafeeds set up.\n",
      "\n",
      "Our trading universe for 1d candles is\n",
      "- 1488 pairs\n",
      "- 177673 candles\n",
      "- 142086 liquidity samples\n",
      "\n",
      "The source data for 1d has\n",
      "- 77030 pairs\n",
      "- 3759703 candles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tradingstrategy.frameworks.qstrader import prepare_candles_for_qstrader\n",
    "from tradingstrategy.liquidity import GroupedLiquidityUniverse\n",
    "from tradingstrategy.pair import PandasPairUniverse\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradingstrategy.candle import GroupedCandleUniverse\n",
    "from tradingstrategy.exchange import ExchangeUniverse, Exchange\n",
    "\n",
    "\n",
    "def prefilter_pairs(all_pairs_dataframe: pd.DataFrame, exchange: Exchange) -> pd.DataFrame:\n",
    "    \"\"\"Get rid of pairs that we definitely are not interested in.\n",
    "\n",
    "    This will greatly speed up the later backtesting computations, as we do not need to\n",
    "    calculate the opening volumes for thousands of pairs.\n",
    "\n",
    "    Note that may induce survivorship bias - we use this mainly\n",
    "    to ensure the backtetst completes in a reasonable time.\n",
    "    \"\"\"\n",
    "    pairs: pd.DataFrame = all_pairs_dataframe.loc[\n",
    "        (all_pairs_dataframe['exchange_id'] == exchange.exchange_id) &\n",
    "        (all_pairs_dataframe['buy_volume_all_time'] > prefilter_min_buy_volume)  # 500k min buys\n",
    "    ]\n",
    "    return pairs\n",
    "\n",
    "exchange_universe = client.fetch_exchange_universe()\n",
    "\n",
    "# Do some test calculations for a single pair\n",
    "# Note that PancakeSwap has two different deployments:\n",
    "# you most likely want v2\n",
    "our_exchange = exchange_universe.get_by_chain_and_slug(ChainId.bsc, \"pancakeswap-v2\")\n",
    "assert our_exchange, \"Could not find the DEX\"\n",
    "\n",
    "# Decompress the pair dataset to Python map\n",
    "columnar_pair_table = client.fetch_pair_universe()\n",
    "\n",
    "# Make our universe 40x smaller and faster to compute\n",
    "filtered_pairs = prefilter_pairs(columnar_pair_table.to_pandas(), our_exchange)\n",
    "\n",
    "# Make the trading pair data easily accessible\n",
    "pair_universe = PandasPairUniverse(filtered_pairs)\n",
    "wanted_pair_ids = pair_universe.get_all_pair_ids()\n",
    "\n",
    "# Get daily candles as Pandas DataFrame\n",
    "all_candles = client.fetch_all_candles(candle_time_frame).to_pandas()\n",
    "filtered_candles = all_candles.loc[all_candles[\"pair_id\"].isin(wanted_pair_ids)]\n",
    "candle_universe = GroupedCandleUniverse(prepare_candles_for_qstrader(filtered_candles), timestamp_column=\"Date\")\n",
    "\n",
    "all_liquidity = client.fetch_all_liquidity_samples(TimeBucket.d1).to_pandas()\n",
    "filtered_liquidity = all_liquidity.loc[all_liquidity[\"pair_id\"].isin(wanted_pair_ids)]\n",
    "filtered_liquidity = filtered_liquidity.set_index(filtered_liquidity[\"timestamp\"])\n",
    "liquidity_universe = GroupedLiquidityUniverse(filtered_liquidity)\n",
    "\n",
    "print(f\"\"\"\n",
    "Datafeeds set up.\n",
    "\n",
    "Our trading universe for {candle_time_frame.value} candles is\n",
    "- {len(wanted_pair_ids)} pairs\n",
    "- {len(filtered_candles)} candles\n",
    "- {len(filtered_liquidity)} liquidity samples\n",
    "\n",
    "The source data for {candle_time_frame.value} has\n",
    "- {len(columnar_pair_table)} pairs\n",
    "- {len(all_candles)} candles\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the alpha model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from qstrader.alpha_model.alpha_model import AlphaModel\n",
    "\n",
    "\n",
    "def update_pair_liquidity_threshold(\n",
    "        now_: pd.Timestamp,\n",
    "        threshold: float,\n",
    "        reached_state: dict,\n",
    "        pair_universe: PandasPairUniverse,\n",
    "        liquidity_universe: GroupedLiquidityUniverse) -> dict:\n",
    "    \"\"\"Check which pairs reach the liquidity threshold on a given day.\n",
    "\n",
    "    :param threshold: Available liquidity, in US dollar\n",
    "\n",
    "    :return: Dict of pair ids who reached the liquidity threshold and how much liquidity they had\n",
    "    \"\"\"\n",
    "\n",
    "    new_entries = {}\n",
    "\n",
    "    # QSTrader carries hours in its timestamp like\n",
    "    # Timestamp('2020-10-01 14:30:00+0000', tz='UTC')\n",
    "    # as it follows NYSE market open and close timestamps.\n",
    "    # Capitalgram candle timestamps are in days and mightnight, so we fix it here.\n",
    "    ts = pd.Timestamp(now_.date())\n",
    "\n",
    "    for pair_id in pair_universe.get_all_pair_ids():\n",
    "\n",
    "        # Skip pairs we know reached liquidity threshold earlier\n",
    "        if pair_id not in reached_state:\n",
    "            # Get the todays liquidity\n",
    "            liquidity_samples = liquidity_universe.get_samples_by_pair(pair_id)\n",
    "            # We determine the available liquidity by the daily open\n",
    "            try:\n",
    "                liquidity_today = liquidity_samples[\"open\"][ts]\n",
    "            except KeyError:\n",
    "                liquidity_today = 0\n",
    "\n",
    "            if liquidity_today >= threshold:\n",
    "                reached_state[pair_id] = now_\n",
    "                new_entries[pair_id] = liquidity_today\n",
    "\n",
    "    return new_entries\n",
    "\n",
    "\n",
    "class MomentumAlphaModel(AlphaModel):\n",
    "    \"\"\"An alpha model that ranks pairs by the daily upwords momentum.\n",
    "\n",
    "    A AlphaModel that provides a single scalar forecast\n",
    "    value for each Asset in the Universe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_weights : `dict{str: float}`\n",
    "        The signal weights per asset symbol.\n",
    "    universe : `Universe`, optional\n",
    "        The Assets to make signal forecasts for.\n",
    "    data_handler : `DataHandler`, optional\n",
    "        An optional DataHandler used to preserve interface across AlphaModels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            exchange_universe: ExchangeUniverse,\n",
    "            pair_universe: PandasPairUniverse,\n",
    "            candle_universe: GroupedCandleUniverse,\n",
    "            liquidity_universe: GroupedLiquidityUniverse,\n",
    "            min_liquidity,\n",
    "            max_assets_per_portfolio,\n",
    "            data_handler=None\n",
    "    ):\n",
    "        self.exchange_universe = exchange_universe\n",
    "        self.pair_universe = pair_universe\n",
    "        self.candle_universe = candle_universe\n",
    "        self.liquidity_universe = liquidity_universe\n",
    "        self.data_handler = data_handler\n",
    "        self.min_liquidity = min_liquidity\n",
    "        self.max_assets_per_portfolio = max_assets_per_portfolio\n",
    "        self.liquidity_reached_state = {}\n",
    "\n",
    "    def construct_shopping_basked(self, dt: pd.Timestamp, new_entries: dict) -> Dict[int, float]:\n",
    "        \"\"\"Construct a pair id \"\"\"\n",
    "\n",
    "        # Sort entire by volume\n",
    "        sorted_by_volume = sorted(new_entries.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Weight all entries equally based on our maximum N entries size\n",
    "        pick_count = min(len(sorted_by_volume), self.max_assets_per_portfolio)\n",
    "\n",
    "        ts = pd.Timestamp(dt.date())\n",
    "\n",
    "        if pick_count:\n",
    "            weight = 1.0 / pick_count\n",
    "            picked = {}\n",
    "            for i in range(pick_count):\n",
    "                pair_id, vol = sorted_by_volume[i]\n",
    "\n",
    "                # An asset may have liquidity added, but not a single trade yet (EURS-USDC on 2020-10-1)\n",
    "                # Ignore them, because we cannot backtest something with no OHLCV data\n",
    "                candles = self.candle_universe.get_candles_by_pair(pair_id)\n",
    "\n",
    "                # Note daily bars here, not open-close bars as internally used by QSTrader\n",
    "                if ts not in candles[\"Close\"]:\n",
    "                    name = self.translate_pair(pair_id)\n",
    "                    logger.warning(\"Tried to trade too early %s at %s\", name, ts)\n",
    "                    continue\n",
    "\n",
    "                picked[pair_id] = weight\n",
    "\n",
    "            return picked\n",
    "\n",
    "        # No new feasible assets today\n",
    "        return {}\n",
    "\n",
    "    def translate_pair(self, pair_id: int) -> str:\n",
    "        \"\"\"Make pari ids human readable for logging.\"\"\"\n",
    "        pair_info = self.pair_universe.get_pair_by_id(pair_id)\n",
    "        return pair_info.get_friendly_name(self.exchange_universe)\n",
    "\n",
    "    def __call__(self, ts: pd.Timestamp) -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        Produce the dictionary of scalar signals for\n",
    "        each of the Asset instances within the Universe.\n",
    "\n",
    "        :param ts: Candle timestamp iterator\n",
    "\n",
    "        :return: Dict(pair_id, alpha signal)\n",
    "        \"\"\"\n",
    "\n",
    "        # Refresh which cross the liquidity threshold today\n",
    "        #new_entries = update_pair_liquidity_threshold(\n",
    "        #    dt,\n",
    "        #    self.min_liquidity,\n",
    "        #    self.liquidity_reached_state,\n",
    "        #    self.pair_universe,\n",
    "        #    self.liquidity_universe\n",
    "        #)\n",
    "        #print(\"New entries coming to the market %zs %s\", dt, new_entries)\n",
    "        #picked = self.construct_shopping_basked(dt, new_entries)\n",
    "\n",
    "        # For each pair, check the the diff between opening and closingn price\n",
    "\n",
    "        samples = self.candle_universe.get_all_samples_by_timestamp(ts)\n",
    "        return picked\n",
    "\n",
    "print(\"Alpha model created\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up the strategy backtest\n",
    "\n",
    "We have alpha model and trading universe set up, so next we will create a backtest simulation\n",
    "where we feed all the data we set up for the backtest session."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qstrader.asset.universe.static import StaticUniverse\n",
    "from qstrader.data.backtest_data_handler import BacktestDataHandler\n",
    "from qstrader.simulation.event import SimulationEvent\n",
    "from qstrader.simulation.everyday import EverydaySimulationEngine\n",
    "from qstrader.trading.backtest import BacktestTradingSession\n",
    "from tradingstrategy.frameworks.qstrader import CapitalgramDataSource\n",
    "\n",
    "data_source = CapitalgramDataSource(exchange_universe, pair_universe, candle_universe)\n",
    "\n",
    "strategy_assets = list(data_source.asset_bar_frames.keys())\n",
    "strategy_universe = StaticUniverse(strategy_assets)\n",
    "\n",
    "data_handler = BacktestDataHandler(strategy_universe, data_sources=[data_source])\n",
    "\n",
    "# Construct an Alpha Model that simply provides a fixed\n",
    "# signal for the single GLD ETF at 100% allocation\n",
    "# with a backtest that does not rebalance\n",
    "strategy_alpha_model = MomentumAlphaModel(\n",
    "    exchange_universe,\n",
    "    pair_universe,\n",
    "    candle_universe,\n",
    "    liquidity_universe,\n",
    "    min_liquidity,\n",
    "    max_assets_per_portfolio)\n",
    "\n",
    "strategy_backtest = BacktestTradingSession(\n",
    "    start,\n",
    "    end,\n",
    "    strategy_universe,\n",
    "    strategy_alpha_model,\n",
    "    initial_cash=initial_cash,\n",
    "    rebalance='daily',\n",
    "    long_only=True,  # Spot markets do not support shorting\n",
    "    cash_buffer_percentage=cash_buffer,\n",
    "    data_handler=data_handler,\n",
    "    simulation_engine=EverydaySimulationEngine(start, end)\n",
    ")\n",
    "\n",
    "print(\"Strategy set up complete\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running the strategy backtest\n",
    "\n",
    "Next we run the strategy. This can take potentially many minutes, as it crunches through some data.\n",
    "\n",
    "The notebook displays a HTML progress bar is displayed during the run, and the estimation when the simulation\n",
    "is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "max_events = len(strategy_backtest.prefetch_simulation_events())\n",
    "\n",
    "# Run the test with a nice progress bar\n",
    "with tqdm(total=max_events) as progress_bar:\n",
    "    def progress_callback(idx: int, dt: pd.Timestamp, evt: SimulationEvent):\n",
    "        progress_bar.set_description(f\"Simulation at day {dt.date()}\")\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    strategy_backtest.run(progress_callback=progress_callback)\n",
    "\n",
    "print(\"Backtest complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-69593197",
   "language": "python",
   "display_name": "PyCharm (dex-ohlcv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}